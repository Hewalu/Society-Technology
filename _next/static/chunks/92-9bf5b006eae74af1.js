"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[92],{6092:(e,r,t)=>{t.d(r,{D:()=>y});let a={blue_classic_web:{name:"Klassisches Web",hex:"#2E6FDB"},red_social:{name:"Soziale Medien",hex:"#E07A2F"},green_academic:{name:"Wissenschaft",hex:"#2FAF7D"},yellow_proprietary:{name:"Propriet\xe4r",hex:"#7A5FD6"},gray_synthetic:{name:"Synthetisch",hex:"#C84FB7"}},n={OpenAI:"US-Anbieter mit Fokus auf dialogstarke, multimodale Foundation-Modelle.","Google DeepMind":"Google AI-Forschung f\xfcr skalierbare, multimodale Systeme und Recherche.",Google:"Google Research mit Schwerpunkt auf skalierbaren Sprach- und Code-Modellen.",Anthropic:"Sicherheitsorientiertes KI-Startup mit der Claude-Reihe f\xfcr verl\xe4ssliche Antworten.",Meta:"Open-Source-orientierte Modelle mit Fokus auf Anpassbarkeit und gro\xdfe Communities.",xAI:"Echtzeit- und Social-Daten getriebene Modelle mit Fokus auf multimodale F\xe4higkeiten.","Aleph Alpha":"Europ\xe4ischer Anbieter mit Transparenzfokus und mehrsprachigen Sprachmodellen."},s="gesch\xe4tzt",i=e=>e.toLowerCase().replace(/[^a-z0-9]+/g,"-").replace(/^-+|-+$/g,""),o=(e,r,t)=>Math.min(Math.max(e,r),t),l=e=>{if(!e||e<=0)return null;let r=Math.pow(o((Math.log10(e)-11)/3.0600000000000005,0,1),1);return Math.round(o(0+3e3*r,0,3e3))},c=e=>{let r=l(e.tokens);if(null!==r)return{points:r,note:null};let t=l("number"==typeof e.parameters&&e.parameters>0?20*e.parameters:null);return null!==t?{points:t,note:s}:{points:1200,note:s}},_=e=>Math.round(24+72*(o(e,0,100)/100)),d=e=>Math.round((100-o(e,0,100))/100*1200)/100,p=e=>{let r=Object.entries(e).filter(e=>{let[,r]=e;return r>0}).map(e=>{let[r,t]=e,n=a[r];return{name:n.name,hex:n.hex,ratio:t}});return 0===r.length?[{name:"Unbekannt",hex:"#334155",ratio:100}]:r},m=e=>{let[r,t]=Object.entries(e).reduce((e,r)=>{let[t,a]=r;return a>e[1]?[t,a]:e},[null,0]);return!r||t<=0?null:"H\xf6chster Anteil: ".concat(a[r].name," (").concat(t,"%).")},g=e=>[e.diversity.rationale.trim(),e.training.notes.trim()].filter(Boolean).map(e=>e.endsWith(".")?e:"".concat(e,".")).join(" "),h=new Map;for(let e of[{provider:"OpenAI",model:"GPT-2",release_date:"2019-11-05",training:{tokens:2e10,parameters:15e8,notes:"WebText aus Reddit-Links; Korpus nicht ver\xf6ffentlicht. Tokens gesch\xe4tzt."},diversity:{score_0_100:40,rationale:"Prim\xe4r englisches klassisches Web; kaum Non-English. Gesch\xe4tzte Werte."},sources_breakdown_pct:{blue_classic_web:90,red_social:0,green_academic:2,yellow_proprietary:0,gray_synthetic:8},transparency:{score_0_100:65,rationale:"Methodik dokumentiert, Daten nicht ver\xf6ffentlicht. Gesch\xe4tzte Transparenz."},estimated_flags:{training_tokens:!0,training_parameters:!1,diversity:!0,sources:!0,transparency:!0}},{provider:"OpenAI",model:"GPT-3",release_date:"2020-06-11",training:{tokens:3e11,parameters:175e9,notes:"Paper mit Quellenanteilen (CommonCrawl/WebText/Books/Wikipedia)."},diversity:{score_0_100:55,rationale:"Breites klassisches Web, \xfcberwiegend Englisch; begrenzte Mehrsprachigkeit. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:85,red_social:0,green_academic:3,yellow_proprietary:12,gray_synthetic:0},transparency:{score_0_100:70,rationale:"Detailierter Datenmix im Paper, Korpora nicht offen."},estimated_flags:{training_tokens:!1,training_parameters:!1,diversity:!0,sources:!0,transparency:!1}},{provider:"OpenAI",model:"GPT-3.5",release_date:"2022-11-30",training:{tokens:32e10,parameters:null,notes:"Basis GPT-3 + RLHF/Instruktionsdaten. Tokens gesch\xe4tzt (≈3.0–3.2e11); Parameter nicht offengelegt."},diversity:{score_0_100:58,rationale:"Wie GPT-3 plus Instruktionsdaten; etwas breitere Dom\xe4nen. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:77,red_social:0,green_academic:3,yellow_proprietary:10,gray_synthetic:10},transparency:{score_0_100:40,rationale:"Prozess (RLHF) beschrieben, Datens\xe4tze nicht transparent. Gesch\xe4tzt."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!0}},{provider:"OpenAI",model:"GPT-4",release_date:"2023-03-14",training:{tokens:1e13,parameters:null,notes:"Mindestens ≈1.0e13 Tokens laut Leaks; konkrete Gr\xf6\xdfen nicht publiziert."},diversity:{score_0_100:75,rationale:"Multimodal (Text/Bild), st\xe4rker mehrsprachig; breite Dom\xe4nen. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:55,red_social:5,green_academic:5,yellow_proprietary:10,gray_synthetic:25},transparency:{score_0_100:20,rationale:"Architektur/Datens\xe4tze weitgehend geheim. Gesch\xe4tzte Transparenz."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!0}},{provider:"OpenAI",model:"GPT-5",release_date:"2025-07-08",training:{tokens:114e12,parameters:null,notes:"Gesch\xe4tzt ≈1.14e14 Tokens (Multi-Modal). Konkrete Gr\xf6\xdfen nicht publiziert."},diversity:{score_0_100:75,rationale:"Multimodal (Text/Bild), st\xe4rker mehrsprachig; breite Dom\xe4nen. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:55,red_social:5,green_academic:5,yellow_proprietary:10,gray_synthetic:25},transparency:{score_0_100:20,rationale:"Architektur/Datens\xe4tze weitgehend geheim. Gesch\xe4tzte Transparenz."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!0}},{provider:"Google",model:"PaLM",release_date:"2022-04-04",training:{tokens:78e10,parameters:54e10,notes:"Paper nennt ≈7.8e11 Tokens (780B). Prozentanteile: 50% Social, 27% Web, 13% Books, 4% Wiki, 5% Code, 1% News."},diversity:{score_0_100:62,rationale:"Multilingual + Code; signifikanter Non-English-Anteil. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:33,red_social:50,green_academic:4,yellow_proprietary:12,gray_synthetic:1},transparency:{score_0_100:80,rationale:"Sehr transparente Quellenanteile im Paper."},estimated_flags:{training_tokens:!1,training_parameters:!1,diversity:!0,sources:!1,transparency:!1}},{provider:"Google",model:"PaLM 2",release_date:"2023-05-10",training:{tokens:36e11,parameters:null,notes:"Skalierung gg\xfc. PaLM; Parameter nicht offen. Tokens gesch\xe4tzt."},diversity:{score_0_100:70,rationale:"Stark multilingual, mehr Code/Reasoning. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:40,red_social:20,green_academic:5,yellow_proprietary:10,gray_synthetic:25},transparency:{score_0_100:55,rationale:"Technischer Report, aber ohne pr\xe4zise Datenanteile. Gesch\xe4tzt."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!0}},{provider:"Google",model:"Gemini 1.0 Pro",release_date:"2023-12-06",training:{tokens:75e11,parameters:null,notes:"Nativ multimodal (Text, Code, Bild/Audio). Tokens gesch\xe4tzt (≈5.0e12–1.0e13)."},diversity:{score_0_100:80,rationale:"Sehr hohe Modalit\xe4ts- und Sprachbreite. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:40,red_social:10,green_academic:10,yellow_proprietary:20,gray_synthetic:20},transparency:{score_0_100:20,rationale:"Keine detaillierten Datenspezifika."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!1}},{provider:"Google",model:"Gemini 1.5 Pro",release_date:"2024-05-14",training:{tokens:11e12,parameters:null,notes:"L\xe4ngere Kontexte, multimodal; Tokens gesch\xe4tzt (≈1.0e13–1.2e13)."},diversity:{score_0_100:82,rationale:"Erweiterte Multimodalit\xe4t und Sprachen. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:38,red_social:10,green_academic:10,yellow_proprietary:22,gray_synthetic:20},transparency:{score_0_100:20,rationale:"Wie Gemini 1.0, geringe Transparenz."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!1}},{provider:"Anthropic",model:"Claude 2",release_date:"2023-07-11",training:{tokens:3e12,parameters:7e10,notes:"Tokens gesch\xe4tzt (≈1.0e12–5.0e12); Parametergr\xf6\xdfe ≈70B."},diversity:{score_0_100:55,rationale:"Mehr Code + etwas mehr Nicht-Englisch als v1. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:70,red_social:5,green_academic:5,yellow_proprietary:5,gray_synthetic:15},transparency:{score_0_100:30,rationale:"Geringe Detailoffenlegung."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!1}},{provider:"Anthropic",model:"Claude 3 Opus",release_date:"2024-03-04",training:{tokens:4e13,parameters:null,notes:"Multimodal, neue Trainingspipeline. Tokens gesch\xe4tzt ≈4.0e13."},diversity:{score_0_100:75,rationale:"Multimodal + st\xe4rker mehrsprachig; mehr Code. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:55,red_social:5,green_academic:10,yellow_proprietary:10,gray_synthetic:20},transparency:{score_0_100:35,rationale:"Modellkarte vorhanden, Datenmix unklar. Gesch\xe4tzt."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!0}},{provider:"Meta",model:"LLaMA 2",release_date:"2023-07-18",training:{tokens:2e12,parameters:7e10,notes:"Erweitertes Korpus, mehr Code und Non-English."},diversity:{score_0_100:60,rationale:"Mehrsprachiger/mehr Code als LLaMA1. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:70,red_social:5,green_academic:5,yellow_proprietary:5,gray_synthetic:15},transparency:{score_0_100:70,rationale:"Detaillierte Model Card, offene Gewichte."},estimated_flags:{training_tokens:!1,training_parameters:!1,diversity:!0,sources:!0,transparency:!1}},{provider:"Meta",model:"LLaMA 3",release_date:"2024-04-18",training:{tokens:15e12,parameters:8e9,notes:"Sehr gro\xdfes Tokenvolumen \xfcber Sprachen/Code. Tokens gesch\xe4tzt."},diversity:{score_0_100:65,rationale:"30 Sprachen + 4\xd7 mehr Code gg\xfc. LLaMA2. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:68,red_social:4,green_academic:6,yellow_proprietary:2,gray_synthetic:20},transparency:{score_0_100:65,rationale:"Zahlen/Tokenizer offen, genaue Datenanteile begrenzt. Gesch\xe4tzt."},estimated_flags:{training_tokens:!0,training_parameters:!1,diversity:!0,sources:!0,transparency:!0}},{provider:"Meta",model:"LLaMA 3",release_date:"2024-04-18",training:{tokens:15e12,parameters:8e10,notes:"Tokenvolumen gem. Ank\xfcndigungen; genaue Verteilung unklar. Gesch\xe4tzt."},diversity:{score_0_100:68,rationale:"30 Sprachen, starker Code-Anteil. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:66,red_social:4,green_academic:6,yellow_proprietary:3,gray_synthetic:21},transparency:{score_0_100:65,rationale:"\xc4hnlich 8B; Paper/volle Aufstellung noch knapp. Gesch\xe4tzt."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!0}},{provider:"xAI",model:"Grok-1",release_date:"2023-11-04",training:{tokens:null,parameters:null,notes:"Gro\xdfer Webkorpus + X/Twitter Firehose/Realtime. Keine Gr\xf6\xdfenangaben."},diversity:{score_0_100:57,rationale:"Web + Social-Realtime; prim\xe4r Englisch. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:35,red_social:50,green_academic:2,yellow_proprietary:5,gray_synthetic:8},transparency:{score_0_100:20,rationale:"Keine technischen Berichte/Model Card."},estimated_flags:{training_tokens:!0,training_parameters:!0,diversity:!0,sources:!0,transparency:!1}},{provider:"Aleph Alpha",model:"Luminous Supreme",release_date:"2023-01-15",training:{tokens:588e9,parameters:7e10,notes:"Benchmark/Blog nennt ≈588B Tokens (5 Sprachen)."},diversity:{score_0_100:60,rationale:"5 Kernsprachen, mehrere Dom\xe4nen inkl. Tech/Business. Gesch\xe4tzt."},sources_breakdown_pct:{blue_classic_web:60,red_social:3,green_academic:12,yellow_proprietary:5,gray_synthetic:20},transparency:{score_0_100:70,rationale:"Relativ transparent (Token/Langumfang), keine volle Quellenliste. Gesch\xe4tzt."},estimated_flags:{training_tokens:!1,training_parameters:!1,diversity:!0,sources:!0,transparency:!0}}]){let r=i(e.provider);if(!h.has(r)){var u;h.set(r,{id:r,name:e.provider,summary:null!=(u=n[e.provider])?u:"Modellangebot ohne hinterlegte Zusammenfassung.",models:[]})}let t=h.get(r);if(!t)continue;let a=c(e.training);t.models.push({id:i(e.model),name:e.model,releaseDate:e.release_date,description:g(e),defaults:{points:a.points,pointsNote:a.note,structureDiameter:_(e.diversity.score_0_100),blur:d(e.transparency.score_0_100),colors:p(e.sources_breakdown_pct)},metrics:{training:e.training,diversity:{score:e.diversity.score_0_100,rationale:e.diversity.rationale},transparency:{score:e.transparency.score_0_100,rationale:e.transparency.rationale},sources:e.sources_breakdown_pct,estimatedFlags:e.estimated_flags,insight:m(e.sources_breakdown_pct)}})}let y=Array.from(h.values()).map(e=>({...e,models:e.models.sort((e,r)=>e.releaseDate<r.releaseDate?1:-1)})).sort((e,r)=>e.name.localeCompare(r.name))}}]);